import streamlit as st
import pandas as pd
import requests
import plotly.express as px
from io import BytesIO
from pymongo import MongoClient
from datetime import datetime

st.set_page_config(layout="wide")
st.title("Datele oficiale ale BNS")

# === Sidebar ===
st.sidebar.header("Selectare perioadÄƒ")
frecventa = st.sidebar.selectbox("FrecvenÈ›a datelor", ["Lunar", "Trimestrial", "Anual"])

url_map = {
    "Lunar": "https://statbank.statistica.md/PxWeb/api/v1/ro/40%20Statistica%20economica/21%20EXT/EXT010/serii%20lunare",
    "Trimestrial": "https://statbank.statistica.md/PxWeb/api/v1/ro/40%20Statistica%20economica/21%20EXT/EXT010/serii%20trimestriale",
    "Anual": "https://statbank.statistica.md/PxWeb/api/v1/ro/40%20Statistica%20economica/21%20EXT/EXT010/serii%20anuale"
}
url_base_dir = url_map[frecventa]

# === Alegere serie ===
try:
    res = requests.get(url_base_dir)
    if res.status_code == 200:
        files = res.json()
        fisier_optiuni = {f["text"]: f["id"] for f in files}
        fisier_selectat = st.sidebar.selectbox("SelecteazÄƒ fiÈ™ierul", list(fisier_optiuni.keys()))
        fisier_id = fisier_optiuni[fisier_selectat]
        url_base = f"{url_base_dir}/{fisier_id}"
    else:
        st.error(f"Eroare la accesarea directorului: {res.status_code}")
        st.stop()
except Exception as e:
    st.error(f"Eroare la accesarea directorului: {e}")
    st.stop()

# === Metadate È™i selectare variabile ===
@st.cache_data
def get_metadata(url):
    r = requests.get(url)
    if r.status_code == 200:
        try:
            return r.json()
        except:
            return {}
    return {}

metadata = get_metadata(url_base)

if not metadata or "variables" not in metadata:
    st.warning("Nu s-au putut Ã®ncÄƒrca variabilele pentru acest fiÈ™ier.")
    st.stop()

st.sidebar.header("Filtre disponibile")
dimensiuni = {}
coduri_dim = {}

for dim in metadata["variables"]:
    nume = dim["text"]
    cod = dim["code"]
    valori = dim["values"]
    etichete = dim["valueTexts"]
    optiuni = dict(zip(valori, etichete))
    dimensiuni[nume] = optiuni
    coduri_dim[nume] = cod

selectii = {}
for nume_dim, optiuni in dimensiuni.items():
    chei = list(optiuni.keys())
    etichete = list(optiuni.values())
    selectie = st.sidebar.multiselect(nume_dim, etichete, default=etichete[:1])
    valori_selectate = [chei[etichete.index(s)] for s in selectie]
    if valori_selectate:
        selectii[nume_dim] = valori_selectate

# ===  POST ===
payload = {"query": [], "response": {"format": "json-stat2"}}
for nume_dim, cod in coduri_dim.items():
    valori = selectii.get(nume_dim, list(dimensiuni[nume_dim].keys())[:1])
    payload["query"].append({
        "code": cod,
        "selection": {"filter": "item", "values": valori}
    })


    
# === AfiÈ™are date ===
if st.sidebar.button("AfiÈ™eazÄƒ datele"):
    r = requests.post(url_base, json=payload)
    if r.status_code == 200:
        try:
            data = r.json()
            valori = data["value"]
            categorii = [list(data["dimension"][dim]["category"]["label"].values())
                         for dim in data["dimension"] if dim not in ["id", "size"]]
            index = pd.MultiIndex.from_product(categorii,
                                               names=[dim for dim in data["dimension"] if dim not in ["id", "size"]])
            df = pd.DataFrame(valori, index=index, columns=["Valoare"]).reset_index()

            st.success("Date preluate cu succes!")
           
            # AfiÈ™eazÄƒ denumirea È™i ultima datÄƒ de actualizare Ã®n format european
            fisier_info = next((f for f in files if f["id"] == fisier_id), None)
            if fisier_info:
                denumire = fisier_info["text"]
                raw_date = fisier_info.get("updated", "")[:10]
                try:
                    parsed_date = datetime.strptime(raw_date, "%Y-%m-%d")
                    ultima_data = parsed_date.strftime("%d.%m.%Y")

                    zile_diferenta = (datetime.today() - parsed_date).days
                    if zile_diferenta <= 30:
                         status = "ðŸŸ¢"
                    else:
                         status = "ðŸ”´"

                except:
                    ultima_data = "n/a"
                    status = "â“"
                st.markdown(f"### {denumire}")
                st.markdown(f"**Ultima actualizare:** `{ultima_data}`")
            st.dataframe(df, use_container_width=True)

            # === AnalizÄƒ specificÄƒ pentru frecvenÈ›a anualÄƒ ===
            if frecventa == "Anual":
                st.subheader(" EvoluÈ›ia anualÄƒ È™i ratele de creÈ™tere (%)")

                try:
                    # Grupare valori anuale
                    df_total = df.groupby(["Indicatori", "Ani"])["Valoare"].sum().reset_index()
                    df_total.sort_values(["Indicatori", "Ani"], inplace=True)

                    # Calcul ratÄƒ de creÈ™tere
                    df_total["Valoare_lag"] = df_total.groupby("Indicatori")["Valoare"].shift(1)
                    df_total["RatÄƒ (%)"] = ((df_total["Valoare"] - df_total["Valoare_lag"]) / df_total["Valoare_lag"] * 100).round(2)

                    # Pivot pentru afiÈ™are: 2 rÃ¢nduri per indicator (valoare È™i ratÄƒ)
                    df_val = df_total.pivot(index="Indicatori", columns="Ani", values="Valoare").round(2)
                    df_rate = df_total.pivot(index="Indicatori", columns="Ani", values="RatÄƒ (%)").round(2)

                     
                    
                    # Unim valorile È™i ratele Ã®ntr-un singur tabel cu etichete
                    df_combined = pd.concat({
                        'Valoare': df_val,
                        'RatÄƒ (%)': df_rate
                    }, axis=0).sort_index()

                    st.dataframe(df_combined, use_container_width=True)

                    # 2. Ponderi pe grupe de È›Äƒri
                    try:
                        df_pie = df.groupby("Grupe de tari")["Valoare"].sum().reset_index()
                        # VerificÄƒm dacÄƒ existÄƒ doar "Total"
                        if len(df_pie) == 1 and df_pie["Grupe de tari"].iloc[0].lower() == "total":
                            st.info("Diagrama circularÄƒ nu este afiÈ™atÄƒ deoarece datele includ doar totalul.")
                        else:
                            st.markdown("#### Ponderi pe grupe de È›Äƒri (cumulativ):")
                            fig_pie = px.pie(df_pie, names="Grupe de tari", values="Valoare", title="Ponderea pe grupe de È›Äƒri")
                            st.plotly_chart(fig_pie, use_container_width=True)

                    except Exception as e:
                        st.warning(f"Nu s-a putut genera diagrama circularÄƒ: {e}")

                except Exception as e:
                    st.warning(f"Eroare la calculul È™i afiÈ™area evoluÈ›iei anuale: {e}")


            
            # Grafic
            col_timp = next((col for col in df.columns if any(x in col.lower() for x in ["an", "lun", "trimestru", "perioad"])), None)
            if col_timp:
                fig = px.line(df, x=col_timp, y="Valoare", color=df.columns[0], markers=True,
                              title="EvoluÈ›ia indicatorului")
                st.plotly_chart(fig, use_container_width=True)

            # Export Excel
            output = BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df.to_excel(writer, index=False, sheet_name="Date")
            st.download_button("DescarcÄƒ Excel", output.getvalue(),
                               file_name=f"{fisier_id}.xlsx",
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        except Exception as e:
            st.error(f"Eroare la procesarea datelor: {str(e)}")
    else:
        st.error(f"Eroare API (POST): {r.status_code}")




# # === OpÈ›ional: Salvare Ã®n MongoDB ===
# st.sidebar.markdown("---")
# salvare_format = st.sidebar.radio("SalveazÄƒ Ã®n:", ["Excel", "MongoDB"])
# btn = st.sidebar.button("AfiÈ™eazÄƒ È™i salveazÄƒ datele")

# if btn:
#     r = requests.post(url_base, json=payload)
#     if r.status_code == 200:
#         try:
#             data = r.json()
#             valori = data["value"]
#             categorii = [list(data["dimension"][dim]["category"]["label"].values())
#                          for dim in data["dimension"] if dim not in ["id", "size"]]
#             index = pd.MultiIndex.from_product(categorii,
#                                                names=[dim for dim in data["dimension"] if dim not in ["id", "size"]])
#             df = pd.DataFrame(valori, index=index, columns=["Valoare"]).reset_index()

#             st.dataframe(df, use_container_width=True)

#             if salvare_format == "Excel":
#                 output = BytesIO()
#                 with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
#                     df.to_excel(writer, index=False, sheet_name="Date")
#                 st.download_button("DescarcÄƒ Excel", output.getvalue(),
#                                    file_name="exporturi_importuri.xlsx",
#                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
#             elif salvare_format == "MongoDB":
#                 client = MongoClient("mongodb://localhost:27017/")
#                 db = client["statistica"]
#                 collection = db["exporturi_importuri"]
#                 collection.insert_many(df.to_dict(orient="records"))
#                 st.success("Datele au fost salvate Ã®n MongoDB!")
#         except Exception as e:
#             st.error(f"Eroare la procesare: {str(e)}")
#     else:
#         st.error(f"Eroare API (POST): {r.status_code}")
